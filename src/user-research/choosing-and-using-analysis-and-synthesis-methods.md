---
title: Choosing and using analysis and synthesis methods
related_order: 220
last_reviewed_at: 2023-10-04T23:00:00.000Z
---
Our second research principle is to [find the truth, and tell the truth](https://playbook.dxw.com/user-research/#user-research-principles). And getting to that truth depends on the strength of our analysis of research data and synthesis to produce findings.

At dxw, we don’t have a fixed set of approved ways to do analysis and synthesis. But we do need to choose approaches that are appropriate to our research methods, and then apply them well.

We encourage our teams to get involved in analysis and synthesis, so that they understand, trust and can act on the findings we produce together.

This guide lists our favourite books, articles and videos on the analysis and synthesis methods and techniques we use most often. In future we aim to add links to any tools and templates we have created, along with good examples from previous projects.

## Principles and stages of analysis and synthesis

The purpose of analysis and synthesis (sometimes also called sensemaking) is to produce findings (sometimes also called insights) that help our team, and sometimes the wider organisation, make informed decisions, and design and build good services.

### Principles

We do at least an initial analysis and synthesis at the end of each research activity, so that we can quickly [learn, share and adapt](https://playbook.dxw.com/user-research/#user-research-principles).

Later we may [combine different kinds of data and findings](#rich-data-and-big-data) from different research activities to create a coherent picture.

And we plan the pace of our research to avoid building up analysis and synthesis debt.

Our rule of thumb is “one part research to two parts communication”. For a day spent doing interviews, for example, we expect to spend two days on analysis and synthesis, and sharing findings.

In doing analysis and synthesis we want:

* findings and next steps we can justify - as we are often challenged to explain why we have come to those conclusions
* findings we can trace back to our research data - so we can support our findings with anonymised quotes, clips, observations and numbers from our research data, and so we can reconsider and update our findings as we gather more data
* to make analysis and synthesis a team sport - so our colleagues get involved and become advocates for our findings
* a rational and repeatable process - as we do analysis regularly and need to do it efficiently

### Stages

Whatever approach we take, our analysis and synthesis goes through three broad stages:

1. Extract observations, answers and numbers

   Cleaning up our notes, recordings, survey responses, and other research data to produce usable sets of observations (what we saw, what people said), answers (response to questions) and numbers (counts, measures, etc).

1. Identify findings (insights)

   Reviewing our observations, answers and numbers against our research questions to see what meaningful and relevant things we can learn.

1. Decide next steps

   Working with our colleagues to agree what to do in response to the findings, including adapting our research activities, creating new design ideas, or recording issues to resolve.

### Rich data and big data

On most of our projects, we expect to do many different research activities, with different groups of participants. Through these activities we will produce a *rich collection of different kinds of data*, such as notes or transcripts from interviews, videos of usability tests, completed boards or worksheets from workshops, responses from questionnaires. Along with any initial findings we created and shared after each activity.

An important part of our work is triangulating this rich collection to:

* strengthen and increase the credibility of our specific findings
* identify contradictions, gaps and biases that may need further research and analysis to resolve
* create a detailed, coherent and compelling picture of the most important things we have learned across the project, particularly in discovery and alpha projects

On some projects we have access to large, numerical data sets - *big data*. This might be performance data or operational data from a service, data collected by social scientists in government research projects, or government statistics produced by the ONS (Office for National Statistics).

Using this data effectively, and combining it with our other sources, can need significant skills in statistics and numerical analysis. So we may look for support from colleagues with specialist data analysis skills.

### Recommended guidance

* [Practical Empathy by Indi Young](https://rosenfeldmedia.com/books/practical-empathy/)
* [Exposing the Magic of Design by Jon Kolko](https://global.oup.com/academic/product/exposing-the-magic-of-design-9780190276218)
* [Triangulation: Get Better Research Results by Using Multiple UX Methods by NN/g](https://www.nngroup.com/articles/triangulation-better-research-results-using-multiple-ux-methods/)
* [The Good Research Guide by Martyn Denscombe](https://www.mheducation.co.uk/the-good-research-guide-research-methods-for-small-scale-social-research-projects-9780335249831-emea-group)
* [Integrating Analyses in Mixed Methods Research by Pat Bazeley](https://methods.sagepub.com/book/integrating-analyses-in-mixed-methods-research)

## Affinity sorting

The method we use most often is affinity sorting (or diagramming). It works well with many research methods, including interviews and observation, and in producing profiles and personas.

We typically do two-level sorts, where we:

1. First group observations into broad categories

   In an application process, for example, we might have a group of observations about providing a photo and another about providing an address.

1. Then break those larger groups into smaller groups of matching observations.

   In the application example, several participants may not want important deliveries sent to their home address, because they share a front door and post often goes missing, so we group those together.

Once we have created the two level grouping, we review them to identify and add statements of our findings.

For collaborative affinity sorting to work well, it’s important that we help colleagues to extract good observations from their notes and other sources. 

### Recommended guidance

* [Affinity Diagramming for Collaboratively Sorting UX Findings and Design Ideas by NN/g](https://www.nngroup.com/articles/affinity-diagram/)
* [What is an affinity diagram and how do you use it? by Miro](https://miro.com/blog/create-affinity-diagrams/)
* [How we do research analysis in agile](https://userresearch.blog.gov.uk/2014/06/05/how-we-do-research-analysis-in-agile/)

## Annotating design artefacts

This is a common variant of affinity sorting that we use in workshops, concept testing, content research and usability testing. In this method we use things like the steps in a process map, a set of design concepts, pieces of content or a set of interface screenshots to define the top level groups.

In this approach we:

1. First place observations against the relevant part of an artefact

   In a workshop reviewing a process map, for example, we place all our observations against the appropriate step.

2. Then review the observations to create smaller groups of matching observations

   In the process map review example, several participants may use the same workaround at the same step.

Once we have created these smaller groups, we review them to identify and add statements of our findings.

We often have observations that seem relevant to our research questions but don’t relate directly to an artefact. So we keep a place to create and review additional groups.

This method works well with less experienced colleagues, and when we want to involve participants in analysis and synthesis, as they can find it difficult to create good first level groups. In that case, it’s particularly important that we help colleagues and participants to attach clear and relevant observations, rather than jump to conclusions and next steps. 

### Recommended guidance

* [Anatomy of a good sticky note](https://userresearch.blog.gov.uk/2014/10/29/anatomy-of-a-good-sticky-note/)
* [Research tips posters](https://github.com/alphagov/govdesign/blob/main/Poster_UserResearchTips.pdf)

## Reviewing existing information

One of our research principles is to [build on existing evidence](https://playbook.dxw.com/user-research/#user-research-principles), combining existing knowledge, poorly understood data and new research into a coherent picture.

So an important source of our findings, particularly in discovery projects, is existing information, whether from inside or outside the client organisation. These sources might be previous discovery reports, service performance investigations, government and industry statistics, and government and third-sector social research.

It can be hard to find and access all the relevant previous and current work that might be useful. We collect and review information that our clients and other stakeholders provide. And we actively seek other sources, including asking stakeholders for the reports, analyses and other evidence that have informed their views.

When reviewing existing information, we are guided by our research questions, and apply the 3 stages of analysis and synthesis (from observations, to findings and actions).

We use our research questions to help us choose information sources, and to choose which parts to review in detail.

Some sources may include meaningful and relevant findings that we can incorporate directly into ours. From others we may need to extract useful observations, answers and numbers that we can bring into our analysis and synthesis. Some previous research may not have been done or presented in ways we would expect, but we work through any limitations to learn what we can.

And we make sure we can trace relevant findings back to the source material.

### Recommended guidance

* [Secondary Research in UX by NN/g](https://www.nngroup.com/articles/secondary-research-in-ux/)
* [Primary, Secondary & Tertiary Sources at Grad Coach](https://gradcoach.com/primary-secondary-tertiary-sources/)

## Quantitative data analysis

Some of our research methods produce numbers, or data that we can turn into numbers. In quantitative data analysis we explore these numbers to help us produce meaningful and relevant findings.

The numbers most often come from surveys and service performance measures. But they can also come from unmoderated usability testing and content research.

Our quantitative data analyses are usually relatively simple, because we rarely do research that generates large amounts of quantitative data.

We typically look at things like:

* totals - such as the number of tests
* proportions - such as the number of tests where users were successful
* ranges - such as the minimum, maximum, mean (average) and median (middle) among the completion times
* distributions - such as the modes (peaks) and skewness (asymmetry) among completion times
* groupings - such as how success and completion times vary for different groups of users
* trends - such as how success and completion times vary over time

For more complicated analysis, particularly where we have access to [bigger and more complicated data sets](#rich-data-and-big-data), we can call on colleagues with specialist data analysis skills for support.

With quantitative analysis, we always remember that numbers themselves are not findings. We work out what the numbers mean for us, and produce meaningful and relevant findings, supported by the numbers, that others can understand and act on.

### Recommended guidance

* [Analysing Quantitative Data by NN/g](https://www.nngroup.com/articles/quantitative-research-study-guide/#analyzing)
* [Quantitative data analysis 101 at Grad Coach](https://gradcoach.com/quantitative-data-analysis-methods/)
* [Surveys that Work by Caroline Jarrett](https://www.effortmark.co.uk/surveysthatwork/)
* [Part 3 of training for Essex Council](https://docs.google.com/presentation/d/16dHXYwXhsZ5lGzNLlJdn6ypbbLPAa-G6rGddsp7jqHo/)

## Coding text and media

Coding is an analysis method we use when we have lots of notes or recordings, and need a systematic way to break down the data. We most often use coding following interviews, observation and contextual research, and large scale surveys.

We first go through your notes or recordings labelling lines or text or parts of the recordings with ‘codes’, and then use the codes to explore patterns or themes.

There are a number of ways we can create the codes. We can start with a set of predefined codes derived from our research questions, or create the codes as we review the data.

### Recommended guidance

* [How to Analyze Qualitative Data from UX Research: Thematic Analysis](https://www.nngroup.com/articles/thematic-analysis/)
* [Qualitative data coding 101 at Grad Coach](https://gradcoach.com/qualitative-data-coding-101/)
* [An Introduction to Codes and Coding by Saldana (book chapter)](https://www.sagepub.com/sites/default/files/upm-binaries/24614_01_Saldana_Ch_01.pdf)
* [Grounded Theory: A Practical Guide by Birks and Mills](https://uk.sagepub.com/en-gb/eur/grounded-theory/book243177)
* [Qualitative Data Analysis: A Methods Sourcebook by Miles, Huberman and Saldana](https://us.sagepub.com/en-us/nam/qualitative-data-analysis/book246128)
(quite expensive new, but can often get cheaper second hand copies)
